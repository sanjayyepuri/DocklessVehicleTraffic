{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dockless Scooter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib, shapely, geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_to_name = {\n",
    "    '000204': \"Triangle\",\n",
    "    '000500': \"North Campus\",\n",
    "    '000700': \"South Campus\",\n",
    "    '000401': \"East Campus\",\n",
    "    '000604': \"Lower West Campus\",\n",
    "    '000603': \"Upper West Campus\",\n",
    "    '000601': \"Campus\"\n",
    "}\n",
    "\n",
    "tract_to_index = {\n",
    "    '000204': 0,\n",
    "    '000500': 1,\n",
    "    '000700': 2,\n",
    "    '000401': 3,\n",
    "    '000604': 4,\n",
    "    '000603': 5,\n",
    "    '000601': 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "scooter_data = pd.read_csv('~/work/data/Dockless_Vehicle_Trips.csv')\n",
    "austin_data = austin = geopandas.GeoDataFrame.from_file('/home/jovyan/work/data/census_tracts_2010_msa/census_tracts_2010_msa.shp',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the first 6 digits of the tract start and end ids and converting to a numerical type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Device ID</th>\n",
       "      <th>Vehicle Type</th>\n",
       "      <th>Trip Duration</th>\n",
       "      <th>Trip Distance</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Modified Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>Council District (Start)</th>\n",
       "      <th>Council District (End)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Census Tract Start</th>\n",
       "      <th>Census Tract End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>606126</th>\n",
       "      <td>e649a626-e182-40e3-8283-d02dff1f0086</td>\n",
       "      <td>b8d5e14a-b19d-49a7-acad-2f4b6ef2dd8d</td>\n",
       "      <td>scooter</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>09/09/2018 12:45:00 PM</td>\n",
       "      <td>09/09/2018 01:00:00 PM</td>\n",
       "      <td>04/17/2019 02:30:05 AM</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>48453001100</td>\n",
       "      <td>48453001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161218</th>\n",
       "      <td>1c295a3f-9766-4f4e-bdb4-a63a6ade1124</td>\n",
       "      <td>260dfc04-ba0c-42c4-9fc8-5797410bf889</td>\n",
       "      <td>scooter</td>\n",
       "      <td>532.0</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>03/07/2019 01:00:00 PM</td>\n",
       "      <td>03/07/2019 01:00:00 PM</td>\n",
       "      <td>04/17/2019 02:35:02 AM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>48453000601</td>\n",
       "      <td>48453000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342908</th>\n",
       "      <td>89e7502a-3a58-4b8f-8596-f5a7dbc5c299</td>\n",
       "      <td>7af67c4e-fc4b-4d5a-b230-575dc343e28a</td>\n",
       "      <td>scooter</td>\n",
       "      <td>184.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>12/08/2018 01:30:00 PM</td>\n",
       "      <td>12/08/2018 01:45:00 PM</td>\n",
       "      <td>04/17/2019 03:25:44 PM</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>48453000601</td>\n",
       "      <td>48453000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415352</th>\n",
       "      <td>cef68c41-f50c-41ee-9b87-979b790ca3f3</td>\n",
       "      <td>78a85ecc-adca-4f76-80bd-ba7fb892bbf2</td>\n",
       "      <td>scooter</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>07/31/2018 10:45:00 AM</td>\n",
       "      <td>07/31/2018 11:15:00 AM</td>\n",
       "      <td>04/17/2019 01:19:05 AM</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>48453001100</td>\n",
       "      <td>48453001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491558</th>\n",
       "      <td>e3d871a0-5e34-4446-b5be-eafbb81b9a3e</td>\n",
       "      <td>f24a1ab0-d070-4acc-8157-35e79527e003</td>\n",
       "      <td>scooter</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>02/02/2019 12:00:00 AM</td>\n",
       "      <td>02/02/2019 12:00:00 AM</td>\n",
       "      <td>04/17/2019 02:42:24 AM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>48453002402</td>\n",
       "      <td>48453002402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ID  \\\n",
       "606126   e649a626-e182-40e3-8283-d02dff1f0086   \n",
       "4161218  1c295a3f-9766-4f4e-bdb4-a63a6ade1124   \n",
       "3342908  89e7502a-3a58-4b8f-8596-f5a7dbc5c299   \n",
       "415352   cef68c41-f50c-41ee-9b87-979b790ca3f3   \n",
       "3491558  e3d871a0-5e34-4446-b5be-eafbb81b9a3e   \n",
       "\n",
       "                                    Device ID Vehicle Type  Trip Duration  \\\n",
       "606126   b8d5e14a-b19d-49a7-acad-2f4b6ef2dd8d      scooter         1048.0   \n",
       "4161218  260dfc04-ba0c-42c4-9fc8-5797410bf889      scooter          532.0   \n",
       "3342908  7af67c4e-fc4b-4d5a-b230-575dc343e28a      scooter          184.0   \n",
       "415352   78a85ecc-adca-4f76-80bd-ba7fb892bbf2      scooter         1912.0   \n",
       "3491558  f24a1ab0-d070-4acc-8157-35e79527e003      scooter          203.0   \n",
       "\n",
       "         Trip Distance              Start Time                End Time  \\\n",
       "606126           675.0  09/09/2018 12:45:00 PM  09/09/2018 01:00:00 PM   \n",
       "4161218         2821.0  03/07/2019 01:00:00 PM  03/07/2019 01:00:00 PM   \n",
       "3342908          543.0  12/08/2018 01:30:00 PM  12/08/2018 01:45:00 PM   \n",
       "415352          2937.0  07/31/2018 10:45:00 AM  07/31/2018 11:15:00 AM   \n",
       "3491558            0.0  02/02/2019 12:00:00 AM  02/02/2019 12:00:00 AM   \n",
       "\n",
       "                  Modified Date  Month  Hour  Day of Week  \\\n",
       "606126   04/17/2019 02:30:05 AM    9.0  12.0          0.0   \n",
       "4161218  04/17/2019 02:35:02 AM    3.0  13.0          4.0   \n",
       "3342908  04/17/2019 03:25:44 PM   12.0  13.0          6.0   \n",
       "415352   04/17/2019 01:19:05 AM    7.0  10.0          2.0   \n",
       "3491558  04/17/2019 02:42:24 AM    2.0   0.0          6.0   \n",
       "\n",
       "         Council District (Start)  Council District (End)    Year  \\\n",
       "606126                        9.0                     9.0  2018.0   \n",
       "4161218                       9.0                     9.0  2019.0   \n",
       "3342908                       9.0                     9.0  2018.0   \n",
       "415352                        9.0                     9.0  2018.0   \n",
       "3491558                       2.0                     2.0  2019.0   \n",
       "\n",
       "        Census Tract Start Census Tract End  \n",
       "606126         48453001100      48453001100  \n",
       "4161218        48453000601      48453000302  \n",
       "3342908        48453000601      48453000603  \n",
       "415352         48453001100      48453001100  \n",
       "3491558        48453002402      48453002402  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scooter_data = scooter_data.dropna(subset=['Census Tract Start'])\n",
    "                                   \n",
    "scooter_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooter_data = scooter_data[scooter_data['Census Tract Start'] != 'OUT_OF_BOUNDS']\n",
    "scooter_data = scooter_data[scooter_data['Census Tract End'] != 'OUT_OF_BOUNDS']\n",
    "scooter_data['Census Tract Start'] = pd.to_numeric(scooter_data['Census Tract Start'])\n",
    "scooter_data['Census Tract End'] = pd.to_numeric(scooter_data['Census Tract End'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tract_to_trunk(tract):\n",
    "    return \"%06d\" % (int(tract) % 1000000)\n",
    "\n",
    "scooter_data['tract_start'] = scooter_data['Census Tract Start'].apply(tract_to_trunk)\n",
    "scooter_data['tract_end'] = scooter_data['Census Tract End'].apply(tract_to_trunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oncampus  = ['000601']\n",
    "offcampus = ['000204', '000500', '000700', '000401', '000604', '000603']\n",
    "scooter_data_starting = scooter_data[scooter_data['tract_start'].isin(oncampus + offcampus)]\n",
    "scooter_data_ending   = scooter_data[scooter_data['tract_end'].isin(oncampus + offcampus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooter_data_raw = pd.read_csv('~/work/data/Dockless_Vehicle_Trips.csv')\n",
    "scooter_data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * (scooter_data_starting.shape[0] / scooter_data_raw.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_freqs = scooter_data_starting.groupby(['tract_start'])['tract_start'].agg('count').to_frame('count').reset_index()\n",
    "start_data = geopandas.GeoDataFrame(pd.merge(start_freqs, austin_data, how='inner', left_on=['tract_start'], right_on=['TRACTCE10']))\n",
    "start_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "start_data.plot(column='count', ax=ax, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_freqs = scooter_data_ending.groupby(['tract_end'])['tract_end'].agg('count').to_frame('count').reset_index()\n",
    "end_data = geopandas.GeoDataFrame(pd.merge(end_freqs, austin_data, how='inner', left_on=['tract_end'], right_on=['TRACTCE10']))\n",
    "end_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "end_data.plot(column='count', ax=ax, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scooter_data_starting.shape, scooter_data_ending.shape)\n",
    "scooter_data_starting.head()\n",
    "merged_data =scooter_data_starting[scooter_data_starting['ID'].isin(scooter_data_ending['ID'])]\n",
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_start_freqs = merged_data.groupby(['tract_start'])['tract_start'].agg('count').to_frame('count').reset_index()\n",
    "merged_end_freqs = merged_data.groupby(['tract_end'])['tract_end'].agg('count').to_frame('count').reset_index()\n",
    "\n",
    "merged_start_data = geopandas.GeoDataFrame(pd.merge(merged_start_freqs, austin_data, how='inner', left_on=['tract_start'], right_on=['TRACTCE10']))\n",
    "merged_end_data = geopandas.GeoDataFrame(pd.merge(merged_end_freqs, austin_data, how='inner', left_on=['tract_end'], right_on=['TRACTCE10']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "merged_start_data.plot(column='count', ax=ax, legend=True, cmap='Pastel2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "merged_end_data.plot(column='count', ax=ax, legend=True, cmap='Pastel2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "d = []\n",
    "d_norm = []\n",
    "labels = []\n",
    "for loc in offcampus:\n",
    "    freq = merged_start_freqs[merged_start_freqs[\"tract_start\"] == loc][\"count\"].iloc[0]\n",
    "    total += freq\n",
    "    labels.append(tract_to_name[str(loc)])\n",
    "    d.append(freq)\n",
    "\n",
    "for loc in offcampus:\n",
    "    freq = merged_start_freqs[merged_start_freqs[\"tract_start\"] == loc][\"count\"].iloc[0]\n",
    "    d_norm.append(freq / total)\n",
    "\n",
    "plt.bar(labels, d, align='center', color='#cc5500', alpha=0.7)\n",
    "plt.ylabel('Start Frequency')\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Scooters Starting Off-Campus')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample a location :-)\n",
    "freqqq = [0]*len(offcampus)\n",
    "for _ in range(1000):\n",
    "    freqqq[tract_to_index[np.random.choice(offcampus, p=d_norm)]] += 1\n",
    "\n",
    "plt.bar(labels, freqqq, align='center', color='#cc5500', alpha=0.7)\n",
    "plt.ylabel('Start Frequency')\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Scooters Starting Off-Campus')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(7, 1,figsize=(15, 10))\n",
    "for i in range(7): # 0 = sunday, 6 = saturday\n",
    "    time_freq = merged_data[merged_data['Day of Week'] == i].groupby(['Hour'])['Hour'].agg('count').to_frame('count').reset_index()\n",
    "    ax[i].plot(time_freq['Hour'], time_freq['count'])\n",
    "    print(time_freq.nlargest(3, \"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['Start Time'] = pd.to_datetime(merged_data['Start Time'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "merged_data['End Time']   = pd.to_datetime(merged_data['End Time'],   format=\"%m/%d/%Y %I:%M:%S %p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['Start Time'].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_decimal(strtime):\n",
    "    hour, minute = map(int, strtime.strftime(\"%H:%M\").split(':'))\n",
    "    return hour + (minute / 60)\n",
    "\n",
    "merged_data['start_hour_decimal'] = merged_data['Start Time'].apply(to_decimal)\n",
    "merged_data['end_hour_decimal'] = merged_data['End Time'].apply(to_decimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(7, 1,figsize=(15, 10))\n",
    "for i in range(7): # 0 = sunday, 6 = saturday\n",
    "    start_time_freq = merged_data[merged_data['Day of Week'] == i].groupby(['start_hour_decimal'])['start_hour_decimal'].agg('count').to_frame('count').reset_index()\n",
    "    end_time_freq   = merged_data[merged_data['Day of Week'] == i].groupby(['end_hour_decimal'])['end_hour_decimal'].agg('count').to_frame('count').reset_index()\n",
    "    ax[i].plot(start_time_freq['start_hour_decimal'], start_time_freq['count'], c=\"blue\")\n",
    "    ax[i].plot(end_time_freq['end_hour_decimal'], end_time_freq['count'], c=\"red\")\n",
    "#     print(time_freq.nlargest(3, \"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_time_distribution(class_time): # P(start_time)\n",
    "    first_time      = class_time - 0.50\n",
    "    second_time     = class_time - 0.25\n",
    "    \n",
    "    start_time_freq = merged_data[merged_data['Day of Week'] == 3].groupby(['start_hour_decimal'])['start_hour_decimal'].agg('count').to_frame('count').reset_index()\n",
    "    first  = int(start_time_freq[start_time_freq['start_hour_decimal'] == first_time]['count'].iloc[0])\n",
    "    second = int(start_time_freq[start_time_freq['start_hour_decimal'] == second_time]['count'].iloc[0])\n",
    "    third  = int(start_time_freq[start_time_freq['start_hour_decimal'] == class_time]['count'].iloc[0])\n",
    "    \n",
    "    first_ln, second_ln, third_ln = np.log(first), np.log(second), np.log(third)\n",
    "    first_piecewise  = LinearRegression().fit(np.array([0,  15]).reshape((-1, 1)), [first,  second])\n",
    "    second_piecewise = LinearRegression().fit(np.array([15, 30]).reshape((-1, 1)), [second_ln, third_ln])\n",
    "    \n",
    "    distribution = {}\n",
    "    total = 0.0\n",
    "    for minute in range(0, 30):\n",
    "        if minute < 15:\n",
    "            total += first_piecewise.predict(np.array([minute]).reshape(1, -1))[0]\n",
    "        else:\n",
    "            total += np.exp(second_piecewise.predict(np.array([minute]).reshape(1, -1))[0])\n",
    "            \n",
    "    for minute in range(0, 30):\n",
    "        t = first_time + (minute / 60)\n",
    "        if minute < 15:\n",
    "            distribution[t] = first_piecewise.predict(np.array([minute]).reshape(1, -1))[0]\n",
    "        else:\n",
    "            distribution[t] = np.exp(second_piecewise.predict(np.array([minute]).reshape(1, -1))[0])\n",
    "\n",
    "        distribution[t] /= total\n",
    "        \n",
    "    squished_dist = {first_time: 0.0, second_time: 0.0}\n",
    "    for minute in range(0, 30):\n",
    "        t = first_time + (minute / 60)\n",
    "        if minute < 15:\n",
    "            squished_dist[first_time] += distribution[t]\n",
    "        else:\n",
    "            squished_dist[second_time] += distribution[t]\n",
    "\n",
    "    return squished_dist\n",
    "\n",
    "distribution = get_start_time_distribution(8.0)\n",
    "print(distribution)\n",
    "\n",
    "distribution = get_start_time_distribution(9.0)\n",
    "print(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_distribution(start_time): # P(distance | start_time)\n",
    "    distances_given_start = merged_data[merged_data[\"start_hour_decimal\"] == start_time]\n",
    "    distances_given_start = distances_given_start[(distances_given_start['Trip Distance'] > 50) & (distances_given_start['Trip Distance'] < 2000)].sort_values(by=['Trip Distance'])\n",
    "    distances_freq = distances_given_start.groupby(['Trip Distance'])['Trip Distance'].agg('count').to_frame('count').reset_index()\n",
    "#     return distances_freq\n",
    "    \n",
    "    # avg pool/smooth data\n",
    "    distances_freq_pooled = {}\n",
    "    total = 0.0\n",
    "    for mid in range(55, 1906, 10):\n",
    "        val = distances_freq[distances_freq['count'].isin(list(range(mid, mid + 10)))].mean()\n",
    "        distances_freq_pooled[mid] = val\n",
    "        total += val\n",
    "        \n",
    "    for mid in range(55, 1906, 10):\n",
    "        distances_freq_pooled[mid] /= total\n",
    "        \n",
    "#     return distances_freq_pooled\n",
    "    x, y = zip(*sorted(distances_freq_pooled.items()))\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_distance_distribution(9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    distances_given_start = merged_data[merged_data[\"start_hour_decimal\"] == 9.5]\n",
    "    distances_given_start = distances_given_start[(distances_given_start['Trip Distance'] > 50) & (distances_given_start['Trip Distance'] < 2000)].sort_values(by=['Trip Distance'])\n",
    "    distances_freq = distances_given_start.groupby(['Trip Distance'])['Trip Distance'].agg('count').to_frame('count').reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
